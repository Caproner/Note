# 模型性能评估

## 查准率/召回率

在二分类问题中，简单地使用准确率来评判模型性能并不好（例如在一个90%几率分类为0的数据集中，全0模型的准确率就可以达到90%，但这并没有意义）

所以引入正负例判别：

| \               | 预测结果为True | 预测结果为False |
| --------------- | -------------- | --------------- |
| 真实结果为True  | TP（真正例）   | FN（假反例）    |
| 真实结果为False | FP（假正例）   | TN（真反例）    |

那么查准率P（precision）定义为`TP/(TP+FP)`，也就是在模型预测为True的case中，准确率有多少

而召回率R（recall）定义为`TP/(TP+FN)`，也就是在真实情况为True的case中，准确率有多少

更通用的指标F1则为`2PR/(P+R)`

